{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'https://slack.com/api'\n",
    "# load in my slack API token\n",
    "with open('token.txt', 'r') as t:\n",
    "    token = t.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to get the channel ID for resources, uses channels.list.  Go ahead and make a dict of all channel names with id's as values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "payload = {\n",
    "    'token' : token\n",
    "}\n",
    "\n",
    "r = requests.get(url='{}/channels.list'.format(url), params=payload)\n",
    "\n",
    "import json\n",
    "\n",
    "response = json.loads(r.text)\n",
    "channels = {item['name'] : item['id'] for item in response['channels']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resources_id = channels['resources']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I can go through and pull the messages from that channel.  I will have to continually make requests to pull more messages until I have them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attachments': [{'fallback': 'Simple tool/library to visualize huge python dict',\n",
       "   'from_url': 'http://stackoverflow.com/a/15024168/6661502',\n",
       "   'id': 1,\n",
       "   'service_icon': 'http://cdn.sstatic.net/Sites/stackoverflow/img/favicon.ico?v=4f32ecc8f43d',\n",
       "   'service_name': 'stackoverflow.com',\n",
       "   'text': \"I have a huge dict structure like this one:my_data = { 'key1': { '_': 'value1': 'aaa' }, 'key2': { '_': 'value2': 'bbb', 'key2.1': { '_': 'ccc', ...\",\n",
       "   'thumb_height': 316,\n",
       "   'thumb_url': 'http://cdn.sstatic.net/Sites/stackoverflow/img/apple-touch-icon@2.png?v=73d79a89bded&a',\n",
       "   'thumb_width': 316,\n",
       "   'title': 'Simple tool/library to visualize huge python dict',\n",
       "   'title_link': 'http://stackoverflow.com/a/15024168/6661502'}],\n",
       " 'text': 'I was looking for a way to display and interact with large dicts today and got this answer to work: <http://stackoverflow.com/a/15024168/6661502>',\n",
       " 'ts': '1478923302.000061',\n",
       " 'type': 'message',\n",
       " 'user': 'U1RJ84JMD'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['messages'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# empty list to contain our dicts\n",
    "message_dicts = []\n",
    "\n",
    "# kick off a first request\n",
    "payload = {\n",
    "    'token' : token,\n",
    "    'channel' : resources_id\n",
    "}\n",
    "\n",
    "r = requests.get(url='{}/channels.history'.format(url), params=payload)\n",
    "response = json.loads(r.text)\n",
    "\n",
    "message_dicts += response['messages']\n",
    "\n",
    "# Are there more messages to pull?\n",
    "if response['has_more']:\n",
    "    done = False\n",
    "else:\n",
    "    done = True\n",
    "    \n",
    "while not done:\n",
    "    if response['has_more'] == False:\n",
    "        done = True\n",
    "    # get ts value for last message id in list to pass as latest param in next call\n",
    "    latest = response['messages'][-1]['ts']\n",
    "    \n",
    "    payload = payload = {\n",
    "        'token' : token,\n",
    "        'channel' : resources_id,\n",
    "        'latest' : latest\n",
    "    }\n",
    "    \n",
    "    r = requests.get(url='{}/channels.history'.format(url), params=payload)\n",
    "    response = json.loads(r.text)\n",
    "    \n",
    "    # add message dicts to list\n",
    "    message_dicts += response['messages']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing the JSON out to file to read in later and parse more stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dump = json.dumps(message_dicts)\n",
    "\n",
    "with open('message_dicts.json', 'w') as m:\n",
    "    m.write(dump)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the code to read it back in.  Make it a code cell to activate it."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open('message_dicts.json', 'r') as m:\n",
    "    message_dicts = json.loads(m.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to try pulling the URL's from each message into a list for further parsing...where we can"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "attachments = [item.setdefault('attachments', None) for item in message_dicts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "urls = [[item[0]['title'], item[0]['from_url']] for item in attachments if item != None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_write = ['{},{}\\n'.format(url[0],url[1]) for url in urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open('urls.txt', 'w') as u:\n",
    "    u.writelines(to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['csurfer/pyheat', 'https://github.com/csurfer/pyheat'],\n",
       " ['Improving your code with container methods - Python Programming',\n",
       "  'https://python-programming.courses/code-mastery/improving-code-container-methods/'],\n",
       " [\"Hacker's guide to Neural Networks\",\n",
       "  'http://karpathy.github.io/neuralnets/'],\n",
       " ['jakevdp/PythonDataScienceHandbook',\n",
       "  'https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/README.md'],\n",
       " ['pandas-dev/pandas',\n",
       "  'https://github.com/pandas-dev/pandas/blob/master/doc/cheatsheet/Pandas_Cheat_Sheet.pdf'],\n",
       " ['airbnb/superset', 'https://github.com/airbnb/superset'],\n",
       " ['lk-geimfari/awesomeo',\n",
       "  'https://github.com/lk-geimfari/awesomeo/blob/master/languages/PYTHON.md'],\n",
       " ['obachem/kmc2',\n",
       "  'https://github.com/obachem/kmc2?__hstc=36392319.c7989f645cc3265cd4938b505d0c5512.1482440390003.1482440390003.1482440390003.1&__hssc=36392319.1.1482440390003&__hsfp=259699018'],\n",
       " ['An Intuitive Explanation of Convolutional Neural Networks | Open Data Science',\n",
       "  'https://www.opendatascience.com/blog/an-intuitive-explanation-of-convolutional-neural-networks/'],\n",
       " ['Hidden features of Python',\n",
       "  'http://stackoverflow.com/questions/101268/hidden-features-of-python'],\n",
       " ['jwkvam/bowtie', 'https://github.com/jwkvam/bowtie'],\n",
       " ['Awesome Python', 'http://awesome-python.com/'],\n",
       " ['Introducing: fastparquet',\n",
       "  'https://www.continuum.io/blog/developer-blog/introducing-fastparquet'],\n",
       " ['An Interactive Tutorial on Numerical Optimization',\n",
       "  'http://www.benfrederickson.com/numerical-optimization/?imm_mid=0eb541&cmp=em-data-na-na-newsltr_20161207'],\n",
       " ['Data School', 'http://www.dataschool.io/'],\n",
       " ['Tweaking4All.com - MacOS X - ApplePi Baker - Prep SD-Cards for IMG or NOOBS',\n",
       "  'http://www.tweaking4all.com/hardware/raspberry-pi/macosx-apple-pi-baker/'],\n",
       " ['Relative imports for the billionth time',\n",
       "  'http://stackoverflow.com/a/14132912/6661502'],\n",
       " ['Simple tool/library to visualize huge python dict',\n",
       "  'http://stackoverflow.com/a/15024168/6661502'],\n",
       " ['Advanced Analytics with Spark: Patterns for Learning from Data at Scale: Sandy Ryza, Uri Laserson, Sean Owen, Josh Wills: 9781491912768: Amazon.com: Books',\n",
       "  'https://www.amazon.com/Advanced-Analytics-Spark-Patterns-Learning/dp/1491912766'],\n",
       " ['DonJayamanne/pythonVSCode',\n",
       "  'https://github.com/DonJayamanne/pythonVSCode/wiki/Jupyter-Examples'],\n",
       " ['Visual Studio Code - Code Editing. Redefined',\n",
       "  'http://code.visualstudio.com/B?utm_expid=101350005-31.YsqwCVJESWmc4UCMDLsNRw.1&utm_referrer=https%3A%2F%2Fwww.google.com%2F#hundreds-of-extensions'],\n",
       " ['rkern/line_profiler', 'https://github.com/rkern/line_profiler'],\n",
       " ['airbnb/knowledge-repo', 'https://github.com/airbnb/knowledge-repo'],\n",
       " ['Raspberry Pi Barcode Scanner in Python',\n",
       "  'https://medium.com/@yushulx/raspberry-pi-barcode-scanner-in-python-927839100c6b#.5qisvcyfn'],\n",
       " ['OSMnx: Python for Street Networks - Geoff Boeing',\n",
       "  'http://geoffboeing.com/2016/11/osmnx-python-street-networks/'],\n",
       " ['spaCy - spaCy', 'https://spacy.io/'],\n",
       " ['Stan ', 'http://mc-stan.org/'],\n",
       " ['CVonline: Image Databases',\n",
       "  'http://homepages.inf.ed.ac.uk/rbf/CVonline/Imagedbase.htm'],\n",
       " ['blue-yonder/tsfresh', 'https://github.com/blue-yonder/tsfresh'],\n",
       " ['Notebook on nbviewer',\n",
       "  'https://nbviewer.jupyter.org/github/knowsuchagency/mpb-sentiment-analysis-example/blob/master/index.ipynb'],\n",
       " ['from PyPi import *', 'https://repl.it/site/blog/python-import'],\n",
       " ['Writing Idiomatic Python Book',\n",
       "  'https://jeffknupp.com/writing-idiomatic-python-ebook/'],\n",
       " ['Python Knowledge Base', 'https://www.quantifiedcode.com/knowledge-base/'],\n",
       " ['Python 201 Book is Free for 48 hours • /r/Python',\n",
       "  'https://www.reddit.com/r/Python/comments/57xaud/python_201_book_is_free_for_48_hours/'],\n",
       " ['Functions | Microsoft Azure',\n",
       "  'https://azure.microsoft.com/en-us/services/functions/'],\n",
       " ['AWS Lambda - Serverless Compute', 'https://aws.amazon.com/lambda'],\n",
       " ['Microsoft/LightGBM',\n",
       "  'https://github.com/Microsoft/LightGBM/wiki/Experiments'],\n",
       " ['Powering geospatial analysis: public geo datasets now on Google Cloud',\n",
       "  'https://cloudplatform.googleblog.com/2016/10/powering-geospatial-analysis-public-geo-datasets-now-on-Google-Cloud.html'],\n",
       " ['Announcing YouTube-8M: A Large and Diverse Labeled Video Dataset for Video Understanding Research',\n",
       "  'https://research.googleblog.com/2016/09/announcing-youtube-8m-large-and-diverse.html?m=1'],\n",
       " ['Introducing the Open Images Dataset',\n",
       "  'https://research.googleblog.com/2016/09/introducing-open-images-dataset.html'],\n",
       " ['18 Free Exploratory Data Analysis Tools For People who don’t code so well',\n",
       "  'https://www.analyticsvidhya.com/blog/2016/09/18-free-exploratory-data-analysis-tools-for-people-who-dont-code-so-well/'],\n",
       " ['The Neural Network Zoo - The Asimov Institute',\n",
       "  'http://www.asimovinstitute.org/neural-network-zoo/'],\n",
       " ['Microsoft Azure Notebooks', 'https://notebooks.azure.com/'],\n",
       " ['PiBakery', 'http://www.pibakery.org/'],\n",
       " ['gnab/remark', 'https://github.com/gnab/remark'],\n",
       " ['cloudera/livy', 'https://github.com/cloudera/livy'],\n",
       " ['PyFlux', 'http://www.pyflux.com/'],\n",
       " ['I want anaconda, but not by\\xa0default',\n",
       "  'https://y3l2n.wordpress.com/2016/09/03/i-want-anaconda-but-not-by-default/'],\n",
       " ['Setting up Sublime Text 3 for Full Stack Python Development - Real Python',\n",
       "  'https://realpython.com/blog/python/setting-up-sublime-text-3-for-full-stack-python-development/'],\n",
       " ['Oh My Zsh', 'http://ohmyz.sh/'],\n",
       " ['jond3k/ipynb_stripout', 'https://github.com/jond3k/ipynb_stripout'],\n",
       " ['code.gov', 'https://code.gov/'],\n",
       " ['apache/incubator-airflow', 'https://github.com/apache/incubator-airflow'],\n",
       " ['jond3k/ipynb_stripout', 'https://github.com/jond3k/ipynb_stripout'],\n",
       " ['List of 50+ Machine Learning APIs',\n",
       "  'http://www.datasciencecentral.com/profiles/blogs/list-of-50-machine-learning-apis']]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
